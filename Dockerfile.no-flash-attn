# HunyuanVideo-Avatar Docker Container WITHOUT Flash Attention
# Fallback option for environments where flash-attn compilation fails

FROM nvidia/cuda:12.4.1-devel-ubuntu22.04

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-dev git wget curl \
    ffmpeg libsm6 libxext6 libxrender-dev \
    libgl1-mesa-glx libglib2.0-0 libgomp1 \
    && rm -rf /var/lib/apt/lists/* \
    && ln -s /usr/bin/python3 /usr/bin/python

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Disable flash attention to avoid import errors
ENV DISABLE_FLASH_ATTN=1
ENV USE_FALLBACK_ATTENTION=1

# Upgrade pip and install core tools
RUN pip3 install --no-cache-dir --upgrade pip setuptools wheel packaging

# Install PyTorch with CUDA 12.4 support
RUN pip3 install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124

# Install core dependencies WITHOUT flash attention
RUN pip3 install --no-cache-dir \
    diffusers==0.33.0 \
    transformers==4.41.2 \
    accelerate==1.1.1 \
    opencv-python==4.9.0.80 \
    pillow>=9.5.0 \
    imageio==2.34.0 \
    imageio-ffmpeg==0.5.1 \
    librosa==0.11.0 \
    soundfile>=0.12.0 \
    numpy==1.24.4 \
    scipy>=1.10.0 \
    einops==0.7.0 \
    omegaconf>=2.3.0 \
    loguru==0.7.2 \
    tqdm==4.66.2 \
    safetensors==0.4.3 \
    psutil>=5.9.0 \
    huggingface-hub[cli]

# Install web interface with compatible versions
RUN pip3 install --no-cache-dir \
    gradio==3.39.0 \
    fastapi==0.104.1 \
    uvicorn==0.24.0 \
    pydantic==2.4.2

# Install memory optimization package
RUN pip3 install --no-cache-dir mmgp==3.4.9

# Set working directory
WORKDIR /workspace

# Copy application code
COPY hymm_sp/ ./hymm_sp/
COPY hymm_gradio/ ./hymm_gradio/
COPY assets/ ./assets/
COPY config_minimal.py ./
COPY *.sh ./
COPY README.md LICENSE ./

# Copy TorchVision compatibility fix files
COPY apply_torchvision_fix.py ./
COPY fix_torchvision_compatibility.py ./
COPY fix_transformers_torchvision.py ./
COPY fix_deep_torchvision_import.py ./
COPY setup_auto_torchvision_fix.sh ./
COPY start_fastapi_with_fix.py ./

# Create necessary directories
RUN mkdir -p /workspace/weights /workspace/outputs /workspace/logs /workspace/inputs

# Copy startup script and make it executable
COPY docker_startup.sh /workspace/
RUN chmod +x /workspace/docker_startup.sh
RUN chmod +x /workspace/*.sh

# Set environment variables for memory optimization
ENV MODEL_BASE=/workspace
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
ENV CUDA_LAUNCH_BLOCKING=1
ENV OMP_NUM_THREADS=4
ENV PYTORCH_NO_CUDA_MEMORY_CACHING=1
ENV CUDA_CACHE_DISABLE=1

# RunPod specific environment
ENV RUNPOD_POD_ID=${RUNPOD_POD_ID:-""}
ENV RUNPOD_PUBLIC_IP=${RUNPOD_PUBLIC_IP:-""}

# Warning about reduced performance without flash attention
RUN echo "‚ö†Ô∏è  WARNING: Running without Flash Attention - performance will be reduced" && \
    echo "   Consider using Dockerfile.flash-attn or Dockerfile.precompiled for better performance"

# Final verification (without flash-attn)
RUN python3 -c "import torch; print(f'üöÄ Ready! PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"

# Expose ports for web interface
EXPOSE 7860 8000 80

# Set startup command
CMD ["/workspace/docker_startup.sh"] 