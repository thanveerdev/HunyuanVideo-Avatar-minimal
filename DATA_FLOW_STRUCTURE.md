# HunyuanVideo-Avatar Directory Data Flow Structure

## ğŸ“ **Input Data Flow**
```
ğŸ“‚ assets/
â”œâ”€â”€ ğŸ“‚ image/
â”‚   â””â”€â”€ 1.png âœ [Face Detection] âœ hymm_sp/data_kits/face_align/
â””â”€â”€ ğŸ“‚ audio/
    â””â”€â”€ 2.WAV âœ [Audio Processing] âœ hymm_sp/data_kits/audio_dataset.py
```

## ğŸŒ **Web Interface Data Flow**
```
ğŸ“‚ hymm_gradio/
â”œâ”€â”€ web_demo.py âœ [Gradio UI] âœ User Interface (Port 7860)
â”œâ”€â”€ fastapi_server.py âœ [REST API] âœ API Endpoints (Port 80)
â””â”€â”€ pipeline_utils.py âœ [Utility Functions] âœ Processing Pipeline
```

## âš™ï¸ **Configuration Data Flow**
```
config_minimal.py âœ [Base Config] âœ hymm_sp/config.py âœ [Runtime Config] âœ Processing Modules
                                          â”œâ”€â”€ constants.py âœ [System Constants]
                                          â””â”€â”€ Global Configuration State
```

## ğŸ§  **Model Weights Data Flow**
```
ğŸ“‚ weights/
â””â”€â”€ ğŸ“‚ ckpts/
    â”œâ”€â”€ ğŸ“‚ hunyuan-video-t2v-720p/
    â”‚   â”œâ”€â”€ transformers/mp_rank_00_model_states.pt âœ [Transformer Model] âœ Core Diffusion
    â”‚   â””â”€â”€ vae/pytorch_model.pt âœ [VAE Weights] âœ Video Encoding/Decoding
    â”œâ”€â”€ ğŸ“‚ llava_llama_image/ âœ [Vision-Language Model] âœ Image Understanding
    â”œâ”€â”€ ğŸ“‚ text_encoder_2/ âœ [Text Encoder] âœ Prompt Processing
    â”œâ”€â”€ ğŸ“‚ whisper-tiny/ âœ [Audio Transcription] âœ Audio Analysis
    â””â”€â”€ ğŸ“‚ det_align/detface.pt âœ [Face Detection] âœ Face Alignment
```

## ğŸ”„ **Core Processing Pipeline Data Flow**
```
ğŸ“‚ hymm_sp/
â”œâ”€â”€ audio_video_inference.py âœ [Main Inference] âœ Video Generation
â”œâ”€â”€ inference.py âœ [Core Logic] âœ Model Orchestration
â”œâ”€â”€ low_memory_inference.py âœ [Memory Optimization] âœ Resource Management
â””â”€â”€ batch_inference.py âœ [Batch Processing] âœ Multiple Inputs
```

## ğŸ­ **Data Processing Modules Flow**
```
ğŸ“‚ hymm_sp/data_kits/
â”œâ”€â”€ face_align/
â”‚   â”œâ”€â”€ detface.py âœ [Face Detection] âœ Face Coordinates
â”‚   â””â”€â”€ align.py âœ [Face Alignment] âœ Normalized Face Data
â”œâ”€â”€ audio_dataset.py âœ [Audio Loading] âœ Audio Tensors
â”œâ”€â”€ audio_preprocessor.py âœ [Audio Processing] âœ Feature Extraction
â””â”€â”€ data_tools.py âœ [Data Utilities] âœ Data Manipulation
```

## ğŸ§¬ **Neural Network Modules Flow**
```
ğŸ“‚ hymm_sp/modules/
â”œâ”€â”€ models_audio.py âœ [Core Model] âœ HYVideoDiffusionTransformer
â”œâ”€â”€ attn_layers.py âœ [Attention Mechanisms] âœ Self/Cross Attention
â”œâ”€â”€ audio_adapters.py âœ [Audio Integration] âœ Audio-Visual Fusion
â”œâ”€â”€ embed_layers.py âœ [Embeddings] âœ Feature Representations
â”œâ”€â”€ mlp_layers.py âœ [Feed Forward] âœ Feature Transformation
â”œâ”€â”€ norm_layers.py âœ [Normalization] âœ Training Stability
â”œâ”€â”€ activation_layers.py âœ [Activations] âœ Nonlinear Functions
â”œâ”€â”€ modulate_layers.py âœ [Modulation] âœ Conditional Generation
â”œâ”€â”€ posemb_layers.py âœ [Position Embeddings] âœ Spatial/Temporal Info
â”œâ”€â”€ token_refiner.py âœ [Token Processing] âœ Feature Refinement
â”œâ”€â”€ fp8_optimization.py âœ [Memory Optimization] âœ Reduced Precision
â””â”€â”€ parallel_states.py âœ [Parallel Processing] âœ Multi-GPU Support
```

## ğŸ¨ **VAE Processing Flow**
```
ğŸ“‚ hymm_sp/vae/
â”œâ”€â”€ autoencoder_kl_causal_3d.py âœ [3D VAE] âœ Video Encoding/Decoding
â”œâ”€â”€ vae.py âœ [VAE Interface] âœ Latent Space Operations
â””â”€â”€ unet_causal_3d_blocks.py âœ [U-Net Blocks] âœ Spatial-Temporal Processing
```

## ğŸŒŠ **Diffusion Pipeline Flow**
```
ğŸ“‚ hymm_sp/diffusion/
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ pipeline_hunyuan_video_audio.py âœ [Main Pipeline] âœ Video Generation
â””â”€â”€ schedulers/
    â””â”€â”€ scheduling_flow_match_discrete.py âœ [Noise Schedule] âœ Denoising Process
```

## ğŸ“ **Text Processing Flow**
```
ğŸ“‚ hymm_sp/text_encoder/
â””â”€â”€ [Text Encoding Modules] âœ [Prompt Processing] âœ Text Embeddings
```

## ğŸ“Š **Data Flow Sequence**

### **1. Input Processing**
```
User Upload âœ assets/ âœ data_kits/ âœ Preprocessed Data
```

### **2. Model Loading**
```
weights/ckpts/ âœ modules/ âœ Loaded Models
```

### **3. Inference Pipeline**
```
Preprocessed Data + Models âœ diffusion/pipelines/ âœ Generated Video
```

### **4. Output Generation**
```
Generated Video âœ Post-processing âœ Final MP4 Output
```

## ğŸ”§ **Testing and Validation Flow**
```
ğŸ“‚ tests/
â”œâ”€â”€ unit/ âœ [Component Testing] âœ Individual Module Validation
â”œâ”€â”€ integration/ âœ [Pipeline Testing] âœ End-to-End Validation
â”œâ”€â”€ performance/ âœ [Performance Testing] âœ Memory/Speed Optimization
â””â”€â”€ system/ âœ [System Testing] âœ Docker/Deployment Validation
```

## ğŸš€ **Deployment Flow**
```
ğŸ“‚ Docker Configuration
â”œâ”€â”€ Dockerfile âœ [Container Build] âœ Production Environment
â”œâ”€â”€ docker-compose.yml âœ [Service Orchestration] âœ Multi-container Setup
â””â”€â”€ docker_startup.sh âœ [Container Startup] âœ Runtime Initialization
```

## ğŸ“ˆ **Memory Management Flow**
```
config_minimal.py âœ Memory Settings âœ fp8_optimization.py âœ Reduced Memory Usage
                                    â”œâ”€â”€ CPU Offloading
                                    â”œâ”€â”€ Model Sharding
                                    â””â”€â”€ Gradient Checkpointing
```

## ğŸ” **Error Handling Flow**
```
Processing Errors âœ helpers.py âœ Error Recovery âœ Fallback Mechanisms
                 â”œâ”€â”€ TorchVision Fixes
                 â”œâ”€â”€ Import Fallbacks
                 â””â”€â”€ Memory Cleanup
```

## ğŸ“‹ **Key Data Types**

| **Stage** | **Input** | **Output** | **Location** |
|-----------|-----------|------------|--------------|
| Face Detection | Raw Image | Face Coordinates | `data_kits/face_align/` |
| Audio Processing | WAV File | Audio Features | `data_kits/audio_dataset.py` |
| Text Encoding | Text Prompt | Text Embeddings | `text_encoder/` |
| VAE Encoding | Video Frames | Latent Vectors | `vae/` |
| Diffusion | Noise + Conditions | Denoised Latents | `diffusion/pipelines/` |
| VAE Decoding | Latent Vectors | Video Frames | `vae/` |
| Post-processing | Raw Video | Final MP4 | Output Pipeline |

## ğŸ¯ **Critical Dependencies**

1. **flash_attn** âœ `modules/models_audio.py` (Required for attention mechanisms)
2. **torchvision** âœ `data_kits/` (Required for image processing)
3. **transformers** âœ `text_encoder/` (Required for text processing)
4. **diffusers** âœ `diffusion/` (Required for diffusion models)
5. **gradio** âœ `hymm_gradio/` (Required for web interface)

## ğŸ’¡ **Optimization Points**

- **Memory**: VAE processing with slicing (`vae_slice_size`)
- **Speed**: Parallel processing in `modules/parallel_states.py`
- **Quality**: FP8 optimization in `modules/fp8_optimization.py`
- **Stability**: Error handling in `helpers.py`